{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "GhaCJvG3Qbz0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import numpy as np\n",
        "import os\n",
        "import gensim\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "xJEQldSgQdnB"
      },
      "outputs": [],
      "source": [
        "CONSTANTS = {\n",
        "    'label': 'default payment next month',\n",
        "    'path': 'preprocessed_upsampled.csv',\n",
        "    'sequence_features': ['PAY_', 'BILL_AMT', 'PAY_AMT'],\n",
        "    'non_sequence_features': ['LIMIT_BAL', 'SEX', 'EDUCATION', 'MARRIAGE', 'AGE'],\n",
        "    'length': 6,\n",
        "    'batch_size': 64,\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "gopXiZ1zQgGJ"
      },
      "outputs": [],
      "source": [
        "class Dataset_seq(Dataset):\n",
        "  def __init__(self, path):\n",
        "    self.data = pd.read_csv(path)\n",
        "    self.label = CONSTANTS['label']\n",
        "    self.features = list(self.data.columns)\n",
        "    self.features.remove(self.label)\n",
        "  \n",
        "  def __getitem__(self, index):\n",
        "    ex = self.data.iloc[index]\n",
        "    label = ex[self.label]\n",
        "    features = ex[self.features]\n",
        "\n",
        "    non_sequential_features = list(features[CONSTANTS['non_sequence_features']].values)\n",
        "\n",
        "    all_features = []\n",
        "\n",
        "    for i in range(1, 1 + CONSTANTS['length']):\n",
        "      seq_i = []\n",
        "      for base_feature in CONSTANTS['sequence_features']:\n",
        "        seq_i.append(features[f'{base_feature}{i}'])\n",
        "      \n",
        "      seq_i += non_sequential_features\n",
        "      all_features.append(seq_i)\n",
        "    \n",
        "    all_features = np.array(all_features)\n",
        "    all_features = all_features.astype(np.double)\n",
        "    all_features = torch.from_numpy(all_features)\n",
        "\n",
        "    all_features = all_features.type(torch.float)\n",
        "\n",
        "    return torch.flatten(all_features), torch.tensor(label, dtype=torch.long)\n",
        "  \n",
        "  def __len__(self):\n",
        "    return self.data.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v1pF78-gbDUF",
        "outputId": "e2e38adb-0ff3-4eb6-89ac-93350be8b1ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "43MtDHjsfxny"
      },
      "outputs": [],
      "source": [
        "data = Dataset_seq(CONSTANTS['path'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eBnDPDGsibXI"
      },
      "source": [
        "# Two Layer GRU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec644906-bdb5-4707-b69f-6e05316b14f1",
        "id": "Anaj1x4LibXJ"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n"
          ]
        }
      ],
      "source": [
        "# Get cpu or gpu device for training.\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using {} device\".format(device))\n",
        "# Define RNN\n",
        "\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.hidden = 150\n",
        "        self.layers = 2\n",
        "        self.lstm = nn.GRU(input_size=48,hidden_size=self.hidden,num_layers=self.layers)\n",
        "        self.linear = nn.Linear(self.hidden,2)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x, h):\n",
        "        out, h = self.lstm(x,h)\n",
        "        \n",
        "        out = self.linear(out)\n",
        "        return out,h\n",
        "\n",
        "    def init_h(self, bsz):\n",
        "        weight = next(self.parameters())\n",
        "        return weight.new_zeros(self.layers, self.hidden)\n",
        "\n",
        "    # def init_c(self, bsz):\n",
        "    #     weight = next(self.parameters())\n",
        "    #     return weight.new_zeros(self.layers, self.hidden)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "L7GWOPX8ibXJ"
      },
      "outputs": [],
      "source": [
        "# Define Loss, Optimizer\n",
        "model2 = NeuralNetwork()\n",
        "model2 = model2.to(device)\n",
        "lr = 1e-3\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model2.parameters(), lr=lr)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min',patience=4,threshold=1e-3, factor=0.4)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "5GGjTlsPibXJ"
      },
      "outputs": [],
      "source": [
        "# Training \n",
        "batch_sz = CONSTANTS['batch_size']\n",
        "data_size = len(data)\n",
        "train_set, valid_set = random_split(data, [40000, 6728])\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=batch_sz, shuffle=True)\n",
        "test_loader = DataLoader(valid_set, batch_size=batch_sz, shuffle=True)\n",
        "# total_loader = DataLoader(data,batch_size = batch_sz, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def metrics(y_true:torch.Tensor, y_pred:torch.Tensor, is_training=False) -> torch.Tensor:\n",
        "    '''Calculate F1 score. Can work with gpu tensors\n",
        "    \n",
        "    The original implmentation is written by Michal Haltuf on Kaggle.\n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    torch.Tensor\n",
        "        `ndim` == 1. 0 <= val <= 1\n",
        "    \n",
        "    Reference\n",
        "    ---------\n",
        "    - https://www.kaggle.com/rejpalcz/best-loss-function-for-f1-score-metric\n",
        "    - https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score\n",
        "    - https://discuss.pytorch.org/t/calculating-precision-recall-and-f1-score-in-case-of-multi-label-classification/28265/6\n",
        "    \n",
        "    '''\n",
        "    assert y_true.ndim == 1\n",
        "    assert y_pred.ndim == 1 or y_pred.ndim == 2\n",
        "    \n",
        "    if y_pred.ndim == 2:\n",
        "        y_pred = y_pred.argmax(dim=1)\n",
        "        \n",
        "    \n",
        "    tp = (y_true * y_pred).sum().to(torch.float32)\n",
        "    tn = ((1 - y_true) * (1 - y_pred)).sum().to(torch.float32)\n",
        "    fp = ((1 - y_true) * y_pred).sum().to(torch.float32)\n",
        "    fn = (y_true * (1 - y_pred)).sum().to(torch.float32)\n",
        "    \n",
        "    epsilon = 1e-7\n",
        "    \n",
        "    precision = tp / (tp + fp + epsilon)\n",
        "    recall = tp / (tp + fn + epsilon)\n",
        "    \n",
        "    f1 = 2* (precision*recall) / (precision + recall + epsilon)\n",
        "    f1.requires_grad = is_training\n",
        "    \n",
        "    return torch.round(precision, decimals=3), torch.round(recall, decimals=3), torch.round(f1, decimals=3)"
      ],
      "metadata": {
        "id": "s2cU6NlkdCdd"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "bbSaF83tibXJ"
      },
      "outputs": [],
      "source": [
        "# train_loader = total_loader\n",
        "\n",
        "def train2():\n",
        "  \n",
        "  h = model2.init_h(batch_sz)\n",
        "  # c = model2.init_c(batch_sz)\n",
        "\n",
        "  epochs = 25\n",
        "\n",
        "  training_loss = []\n",
        "  training_error = []\n",
        "  training_precision = []\n",
        "  training_recall = []\n",
        "  training_f1 = []\n",
        "  val_loss = []\n",
        "  val_error = []\n",
        "  val_precision = []\n",
        "  val_recall = []\n",
        "  val_f1 = []\n",
        "  learning_rates = []\n",
        "  for epoch in range(epochs):\n",
        "    model2.train()\n",
        "    start_time = time.time()\n",
        "    running_loss = 0\n",
        "    correct = 0\n",
        "    flag = 0\n",
        "    preds, targs = [], []\n",
        "\n",
        "    for op_params in optimizer.param_groups:\n",
        "      learning_rates.append(op_params['lr'])\n",
        "\n",
        "    for input,label in train_loader:\n",
        "\n",
        "        input = input.to(device)\n",
        "        label = label.to(device)\n",
        "        model2.zero_grad()\n",
        "        h = h.detach()\n",
        "        # c = c.detach()\n",
        "        output, h = model2(input, h)\n",
        "        output = output.to(device)\n",
        "\n",
        "        loss = criterion(output, label)\n",
        "\n",
        "        _, pred = torch.max(output, 1)\n",
        "        \n",
        "        correct += (pred == label).float().sum().detach().cpu()\n",
        "        loss.backward()\n",
        "\n",
        "        preds.extend(list(pred.detach().cpu()))\n",
        "        targs.extend(label.tolist())\n",
        "\n",
        "        # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
        "        # torch.nn.utils.clip_grad_norm_(model2.parameters(), 0.2)\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        \n",
        "\n",
        "    precision, recall, f1 = metrics(torch.tensor(preds), torch.tensor(targs))\n",
        "    training_loss.append(running_loss/(len(train_loader)))\n",
        "    training_error.append(1 - (correct/(len(train_loader)*batch_sz)))\n",
        "    training_precision.append(precision)\n",
        "    training_recall.append(recall)\n",
        "    training_f1.append(f1)\n",
        "\n",
        "    print('Epoch [{}/{}], Training Loss: {:.4f}, Training Error: {:.4f}, Precision: {:.4f}, Recall: {:.4f}, F1: {:.4f}'.format(epoch+1, epochs, running_loss/(len(train_loader)), 1 - (correct/(len(train_loader)*batch_sz)), precision, recall, f1))\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "  # # Calculate validation loss and error after each epoch\n",
        "\n",
        "    model2.eval()\n",
        "    val_correct = 0\n",
        "    running_loss_val = 0\n",
        "\n",
        "    val_preds, val_targs = [], []\n",
        "   \n",
        "\n",
        "    for input,label in test_loader:\n",
        "      input = input.to(device)\n",
        "      label = label.to(device)\n",
        "\n",
        "      output, _ = model2(input, h)\n",
        "\n",
        "      loss = criterion(output, label)\n",
        "      _, pred = torch.max(output, 1)\n",
        "      val_correct += (pred == label).float().sum().detach().cpu()\n",
        "\n",
        "      running_loss_val += loss.item()\n",
        "\n",
        "      val_preds.extend(list(pred.detach().cpu()))\n",
        "      val_targs.extend(label.tolist())\n",
        "\n",
        "    precision, recall, f1 = metrics(torch.tensor(val_preds), torch.tensor(val_targs))\n",
        "    avg_loss = running_loss_val/len(test_loader)\n",
        "    val_loss.append(avg_loss)\n",
        "    val_error.append(1 - (val_correct/(len(test_loader)*batch_sz)))\n",
        "    val_precision.append(precision)\n",
        "    val_recall.append(recall)\n",
        "    val_f1.append(f1)\n",
        "\n",
        "    print('Epoch [{}/{}], Validation Loss: {:.4f}, Validation Error: {:.4f}, Precision: {:.4f}, Recall: {:.4f}, F1: {:.4f}'.format(epoch+1, epochs, avg_loss, 1 - (val_correct/(len(test_loader)*batch_sz)), precision, recall, f1))\n",
        "    print(\"=\"*30)\n",
        "\n",
        "    scheduler.step(avg_loss)\n",
        "\n",
        "  return training_error, training_loss, training_precision, training_recall, training_f1, val_error, val_loss, val_precision, val_recall, val_f1, learning_rates\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LOhUkpQQibXK"
      },
      "outputs": [],
      "source": [
        "training_error, training_loss, training_precision, training_recall, training_f1, val_error, val_loss, val_precision, val_recall, val_f1, learning_rates = train2()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HH8x97V7ibXK"
      },
      "outputs": [],
      "source": [
        "plt.plot(training_error)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QvG-2bSGibXK"
      },
      "outputs": [],
      "source": [
        "plt.plot(training_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZoRk8cPaibXK"
      },
      "outputs": [],
      "source": [
        "plt.plot(val_error)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(val_loss)"
      ],
      "metadata": {
        "id": "Jpx4XB6HibXK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(learning_rates)"
      ],
      "metadata": {
        "id": "oivElqOuiXfe"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}